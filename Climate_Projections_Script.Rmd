# ISIMIP Project: Download and Data Preprocessing

The **Inter-Sectoral Impact Model Intercomparison Project** develops and provides climate and socioeconomic forcing datasets with a spatial resolution of 1 degree, along with climate projections under SSP-RCP scenarios from 2015 to 2100. 

The datasets from the ISIMIP3b protocol provide bias-corrected CMIP6 climate forcing for historical data and SSP1-RCP2.6, SSP3-RCP7.0, and SSP5-RCP8.5 conditions. The bias adjustment corrects the simulated data based on corrected ERA5 observational data (W5E5).

More information: <https://www.isimip.org/about/>

Try executing the chunks by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*.

### Install or activate the required libraries

```{r}
#install.packages(c("utils", "ecmwfr", "gtools", "ncdf4", "ncdf4.helpers", "reshape2", "tidyverse", "sf"))

library(utils)
library(ecmwfr)
library(gtools)
library(ncdf4)
library(ncdf4.helpers)
library(reshape2)
library(tidyverse)
library(sf)
```

## 1. Set paths and directory

In the next step, you can choose the folder where the results will be stored, and either select a shapefile representing the region (polygon) of interest or choose a CSV file containing the coordinates of interest.

```{r}
# Set the directory for data storage
user_wd <- readline(prompt = "Please enter your directory path: ")
user_wd <- gsub('"', '', user_wd); user_wd <- gsub('\\\\','/',user_wd)

while (!dir.exists(user_wd)) {
  print("Invalid directory. Please enter a valid one.")
  user_wd <- readline(prompt = "Please enter your directory path: ")
  user_wd <- gsub('"', '', user_wd); user_wd <- gsub('\\\\','/',user_wd)
}
print(paste("You entered a valid directory:", user_wd))

# Create the destination folder if it doesn't exist
temp_folder <- "temp_ERA5"
user_wd <- file.path(user_wd, temp_folder)
user_wd <- gsub("//", "/", user_wd)

if (!dir.exists(user_wd)) {
  dir.create(user_wd)
}

# Set the path to a. shapefile or b. CSV file with coordinates 
user_choice <- readline(prompt = "Please enter 'a' to input the location of your shapefile or 'b' to for CSV with coordinates: ")

if (tolower(user_choice) == "a") {
  # Read shapefile
  shp_path <- readline(prompt = "Please enter the path to your shapefile. Example: path/to/your/folder/polygon.shp :")
  shp_path <- gsub('"', '', shp_path); shp_path <- gsub('\\\\','/',shp_path)

  while (!file.exists(shp_path)) {
    print("Invalid file path. Please enter a valid one.")
    shp_path <- readline(prompt = "Please enter the path to your shapefile. Example: path/to/your/folder/polygon.shp :")
    shp_path <- gsub('"', '', shp_path); shp_path <- gsub('\\\\','/',shp_path)
  }

  shp <- st_read(shp_path)
  print(paste("You entered a valid path for the shapefile:", shp_path))

} else if (tolower(user_choice) == "b") {
  # Read CSV
  coord_path <- readline(prompt = "Please enter the path to your CSV with coordinates. Format: two columns latitude longitude. Example: path/to/your/folder/coordinates.csv :")
  coord_path <- gsub('"', '', coord_path); coord_path <- gsub('\\\\','/',coord_path)

  while (!file.exists(coord_path)) {
    print("Invalid file path. Please enter a valid one.")
    coord_path <- readline(prompt = "Please enter the path to your CSV with coordinates. 
                           Format: two columns latitude longitude. Example: path/to/your/folder/coordinates.csv :")
    coord_path <- gsub('"', '', coord_path); coord_path <- gsub('\\\\','/',coord_path)
  }

  coord_df <- read.csv(coord_path)
  print(paste("You entered a valid path for the CSV file:", coord_path))

} else {
  cat("Invalid choice. Please enter 'a' or 'b'.\n")
}
```

## 2. Enter the variable and time window of your interest

After running the following chunk, please answer with the abbreviation -"t2m" for 2m_temperature or "tp" for total_precipitation- of the variable you are interested in.

```{r}
#Enter the variable you are interested in
available <- c("t2m" = "2m_temperature", "tp" = "total_precipitation")
selection <- NA

while (is.na(selection) || !(selection %in% names(available))) {
  selection <- readline(prompt = "Enter the variable you are interested in (abbreviation): ")

  if (!(selection %in% names(available))) {
    print("Invalid variable. Please enter a valid one.")
  }
}

nc_var <- selection
variable <- available[[selection]]
print(paste("Input is valid. Your request will be processed for variable", variable,"."))

#Enter the start and end year you are interested in
current_year <- as.numeric(format(Sys.Date(), "%Y"))
current_month <- as.numeric(format(Sys.Date(), "%m"))
current_day <- as.numeric(format(Sys.Date(), "%d"))
start_year <- NA
end_year <- NA

while (is.na(start_year) || is.na(end_year)) {

  start_year <- as.numeric(readline(prompt = "Enter the start year you are interested in: "))
  
    if (is.na(start_year) || start_year < 1940) {
    print("Error: Invalid input. Please enter a valid numeric value starting from 1940.")
    next  # Restart from the beginning
  }
  
  end_year <- as.numeric(readline(prompt = "Enter the end year you are interested in: "))
  
  if (end_year <= start_year || end_year > current_year) {
    print("Error: End year cannot be smaller than the start year or larger than the current year. Please enter valid years.")
    end_year <- as.numeric(readline(prompt = "Enter the end year you are interested in: "))
  }
}

print(paste0("Input is valid. Your request will be processed from ", start_year, " to ", end_year, ". :)"))
```

## 3. Enter the latitudes and longitudes of the rectangular area you are interested in

```{r}
lat_min_user <- as.numeric(readline("Enter the min latitude (+N -S): "))
lat_max_user <- as.numeric(readline("Enter the max latitude (+N -S): "))
lon_min_user <- as.numeric(readline("Enter the min longitude (+E -W): "))
lon_max_user <- as.numeric(readline("Enter the max longitude (+E -W): "))
```

## 4. Download the dataset of interest

**Connect to the Server where the dataset is located**

The dataset will be downloaded for the assigned variable and years and stored in the pre-determined directory on your local computer.

```{r}
# The following information can be found on your ECMWF account profile:
# key = Personal Access Token provided by ECMWF
# user_email = email address used to sign up for the ECMWF data service

key <- readline(prompt = "Please enter your Personal Access Token: ")
email_user <- readline(prompt = "Please enter your email address used to sign up the ECMWF Web Portal: ")

wf_set_key(key, user = email_user)

# Create folder to store the NetCDF files
nc_files <- dir.create(file.path(user_wd, "nc_files"))
nc_files <- file.path(user_wd, "nc_files")

start_year <- 2002

# Request and download
for (year in start_year:end_year) {
  end_month <- ifelse(year == current_year, current_month, 12)

  request <- list(
    dataset_short_name  = "reanalysis-era5-single-levels",
    product_type   = "reanalysis",
    variable = variable,
    data_format = "netcdf",
    year = as.character(year), 
    month = sprintf("%02d", 1:end_month), 
    day = sprintf("%02d", 1:31), 
    time = c("00:00", "12:00" ),
    area = c(lat_max_user, lon_min_user, lat_min_user, lon_max_user), # Specified as N, W, S, E
    target = sprintf("reanalysis_era5_single_levels_%s_%s.nc", variable, year)    
  )
  
  file <- wf_request(request,
                     user = email_user,
                     transfer = TRUE,
                     path = nc_files,
                     time_out = 5*3600,
                     retry = 30,
                     verbose = TRUE)
}
```

## 5. Preprocessing of ERA5 NetCDF dataset

If you are interested in preprocessing the data for a shapefile, please run the chunks i and ii from section 5.1. If you are interested in a CSV file, please run section 5.2.

After running the following chunks, the results will be stored in a folder called 'results' within your specified working directory.

### 5.1. Shapefile (polygon)

#### i. Average daily values for the region (polygon) of interest

```{r}
# Create folder and empty data frame to store output data
results_shp <- dir.create(file.path(user_wd, "results_shp")) # Results folder
output_daily <- data.frame() # Empty data frame

# List all NetCDF files in the directory
nc_files <- list.files(path = file.path(user_wd, "nc_files"), pattern = "\\.nc$", full.names = TRUE)

# Extract the minimum and maximum coordinates of your shapefile
bbox <- st_bbox(shp)
lat_min <- min(bbox[2])
lat_max <- max(bbox[4])
lon_min <- min(bbox[1])
lon_max <- max(bbox[3])

# Set your region of interest's latitude and longitude range
lat_range <- c(lat_min, lat_max)
lon_range <- c(lon_min, lon_max)

# Iterate through each NetCDF file
for (i in 1:length(nc_files)) {
  
  nc <- nc_open(nc_files[i])
  
  units <- nc[["var"]][[nc_var]][["units"]]
  
  # Extract time array with the order of the two daily measurements at 00:00 and 12:00
  day <- nc[["dim"]][["valid_time"]][["vals"]]
  
  # Convert seconds since 1970-01-01 to a data frame
  time_df <- as.data.frame(day)
  reference_time <- as.POSIXct(gsub("seconds since ", "", time_units))
  time_df$day <- as.POSIXct(day, origin = "1970-01-01", tz = "GMT")
  time_df$day <- format(as.Date(time_df$day), "%Y-%m-%d")
  time_df$time_id <- seq_len(nrow(time_df))
  
  # Find the indices of latitudes and longitudes within your region of interest
  lat <- nc[["dim"]][["latitude"]][["vals"]]
  lon <- nc[["dim"]][["longitude"]][["vals"]]
  
  lat_indices <- which(lat >= lat_range[1] & lat <= lat_range[2])
  lon_indices <- which(lon >= lon_range[1] & lon <= lon_range[2])
  
  # Calculate additional indices to extend the range
  lat_min_index <- max(1, min(lat_indices) - 1)
  lat_max_index <- min(length(lat), max(lat_indices) + 1)
  lon_min_index <- max(1, min(lon_indices) - 1)
  lon_max_index <- min(length(lon), max(lon_indices) + 1)
  
  # Update latitude and longitude indices
  lat_indices <- lat_min_index:lat_max_index
  lon_indices <- lon_min_index:lon_max_index
  
  # Get latitudes and longitudes corresponding to indices
  lat_subset <- lat[lat_indices]
  lon_subset <- lon[lon_indices]
  
  if (nc[["ndims"]] == 4) {
    data_var <- ncvar_get(nc, nc_var, start = c(lon_indices[1], lat_indices[1], 1, 1), 
                          count = c(length(lon_indices), length(lat_indices), 1, -1))
  } else {
    data_var <- ncvar_get(nc, nc_var, start = c(lon_indices[1], lat_indices[1], 1), 
                          count = c(length(lon_indices), length(lat_indices), -1))
  }
  
  # Reshape the daily variable values into a matrix
  n_lon <- dim(data_var)[1]
  n_lat <- dim(data_var)[2]
  var <- dim(data_var)[3]
  
  # Create a matrix and convert it to a data frame
  matrix_var <- array(data = data_var, dim = c(n_lon, n_lat, var))
  df_var <- as.data.frame(melt(matrix_var))
  colnames(df_var) <- c("lon", "lat", "time_id", "var")
  
  # Add corresponding latitude and longitude
  df_var$lat <- rep(lat_subset, each = n_lon)
  df_var$lon <- rep(lon_subset, times = n_lat)
  
  df_var <- merge(df_var, time_df, by = "time_id")
  
  df_var_avg <- df_var %>%
    group_by(day, lat, lon) %>%
    summarise(var = mean(var, na.rm = TRUE), .groups = "keep")
  
  for (d in unique(df_var_avg$day)) {
    # Subset data for the current month
    #d <- df_var_avg$day[1]
    daily_data <- subset(df_var_avg, day == d)
    
    r <- raster(matrix(NA, nrow = length(unique(daily_data$lon)), 
                       ncol = length(unique(daily_data$lat))))
    values(r) <- daily_data$var
    extent(r) <- extent(min(daily_data$lon), max(daily_data$lon), 
                        min(daily_data$lat), max(daily_data$lat))
    proj4string(r) <- CRS("+proj=longlat +datum=WGS84") 
    names(r) <- d
    
    # Extract the mean value for the current raster and region
    #shp <- shp
    shp_polygons_mean <- exact_extract(r, shp, fun = 'mean')
    shp_mean <- mean(shp_polygons_mean, na.rm = TRUE)
    shp_mean <- round(shp_mean, 5)
    
    # Add the time and region information to the extracted data
    extracted_df <- data.frame(date = unique(daily_data$day), value = shp_mean)
    
    # Append the current extracted data to the results data frame
    output_daily <- rbind(output_daily, extracted_df)
  }
  
  nc_close(nc)
  gc()
  
  print(paste0("Results for file ", i, " have been saved. :)"))
}

# Rename the columns 
colnames(output_daily) <- c("Date", paste0(variable," [",units,"]"))

# Export the results as a CSV file
write.csv(output_daily, file.path(user_wd, "results_shp", "shp_output_daily.csv"), row.names = FALSE)

if (exists("output_daily")) {
  print("Data extraction from NetCDF files completed.")
}
```

#### ii. Average monthly values for the region (polygon) of interest

```{r}
month_values <- output_daily
colnames(month_values) <- c("day", "var")

month_values$day <- as.Date(month_values$day, format = "%Y-%m-%d")
month_values$month <- format(month_values$day, "%m") # Create column with correspondent month

# Monthly average values
monthly_av <- month_values %>%
  group_by(year = format(day, "%Y"), month) %>%
  summarise(var = mean(var, na.rm = TRUE))

# Long-term monthly average values
long_term_av <- month_values %>%
  group_by(month) %>%
  summarise(var = mean(var, na.rm = TRUE))

colnames(monthly_av) <- c("Year", "Month", paste0("Monthly av ",variable," [",units,"]"))
colnames(long_term_av) <- c("Month", paste0("Long-term monthly av ",variable," [",units,"]"))

write.csv(monthly_av, file.path(user_wd, "results_shp", "shp__monthly_av.csv"), row.names = FALSE)
write.csv(long_term_av, file.path(user_wd, "results_shp", "shp_long_term_monthly_av.csv"), row.names = FALSE)
```

### 5.2. CSV with coordinates

#### i. Average daily values for the list of coordinates of interest

```{r}
# Create folder to store output data
results_csv <- dir.create(file.path(user_wd, "results_csv"))

# Save csv file with id for each location
colnames(coord_df) <- c("lat", "lon")
coord_df$id <- seq_len(nrow(coord_df))
write.csv(coord_df, file.path(user_wd,  "results_csv", paste0("location_id.csv")), row.names = FALSE)

# List all NetCDF files in the directory
nc_files <- list.files(path = file.path(user_wd, "nc_files"), pattern = "\\.nc$", full.names = TRUE)

# Iterate through each NetCDF file and each row of the coordinates data frame
for (i in 1:nrow(coord_df)) {
  location_output_daily <- data.frame() # Create an empty data frame to store data for each coordinate set
  
  for (j in 1:length(nc_files)) {
    
    nc <- nc_open(nc_files[j])
    
    nc_var <- names(nc$var)
    units <- nc[["var"]][[nc_var]][["units"]]
    
    # Extract time array with the order of the two daily measurements at 00:00 and 12:00
    day <- nc[["dim"]][["time"]][["vals"]]
    time_df <- as.data.frame(day)
    time_df$day <- as.POSIXct(day * 3600, origin = "1900-01-01 00:00:00", tz = "GMT")
    time_df$day <- format(as.Date(time_df$day))
    time_df$time_id <- seq_len(nrow(time_df))
    
    target_lat <- coord_df$lat[i]
    target_lon <- coord_df$lon[i]
    lat_nc <- nc[["dim"]][["latitude"]][["vals"]]
    lon_nc <- nc[["dim"]][["longitude"]][["vals"]]

    # Find the nearest latitude and longitude indices to the target point
    nearest_lat_index <- which.min(abs(lat_nc - target_lat))
    nearest_lon_index <- which.min(abs(lon_nc - target_lon))
    
    if (nc[["ndims"]] == 3) {
      location_data <- ncvar_get(nc, nc_var, start = c(nearest_lon_index, nearest_lat_index, 1),
                                 count = c(1, 1, -1))
    } else if (nc[["ndims"]] == 4) {
      location_data <- ncvar_get(nc, nc_var, start = c(nearest_lon_index, nearest_lat_index, 1, 1),
                                 count = c(1, 1, 1, -1))
    }
    location_data <- as.vector(location_data)
    
    # Create location_df and merge with time_df
    location_df <- merge(
      data.frame(
        time_id = seq_len(length(location_data)),
        var = location_data
      ),
      time_df, by = "time_id"
    )
    
    # Compute daily averages
    location_df <- location_df %>%
      group_by(day) %>%
      summarise(var_avg = mean(var, na.rm = TRUE))
    
    # Reorder columns and rename
    location_df <- location_df %>%
      mutate(
        id = coord_df$id[i],
        lat = coord_df$lat[i],
        long = coord_df$lon[i]
      )
    
    location_df <- location_df[, c(3, 4, 5, 1, 2)]
    colnames(location_df) <- c("Id", "Latitude", "Longitude", "Date", paste0(variable, " [", units, "]"))
    
    # Append to location_output_daily
    location_output_daily <- rbind(location_output_daily, location_df)
    
    nc_close(nc)
  }
  
  # Save the data for the current location to a CSV file
  location_filename <- paste0("location_", i, "_output_daily.csv")
  write.csv(location_output_daily, file.path(user_wd, "results_csv", location_filename), row.names = FALSE)
  
  print(paste0("Results for location ", i, " have been saved. :)"))
}
```

#### ii. Average monthly values for the list of coordinates of interest

```{r}
output_daily <- list.files(file.path(user_wd, "results_csv"), pattern = "location_.*_output_daily.csv", full.names = TRUE)
output_daily <- mixedsort(output_daily)  # Sort the files

for (i in 1:length(output_daily)) {
  location_data <- read.csv(output_daily[1])
  colnames(location_data) <- c("id", "lat", "long", "day", "var")
  
  location_data$day <- as.Date(location_data$day, format = "%Y-%m-%d")
  location_data$month <- format(location_data$day, "%m")
  
  # Compute monthly average values
  monthly_av <- location_data %>%
    group_by(id, lat, long, year = format(day, "%Y"), month) %>%
    summarise(var = mean(var, na.rm = TRUE))
  
  # Compute long-term monthly average
  long_term_av <- location_data %>%
    group_by(id, lat, long, month) %>%
    summarise(var = mean(var, na.rm = TRUE))
  
  # Export results as CSV files
  common_cols <- c("Id", "Lat", "Lon")
  colnames(monthly_av) <- c(common_cols, "Year", "Month", paste0("Monthly av ",variable," [",units,"]"))
  colnames(long_term_av) <- c(common_cols, "Month", paste0("Long-term monthly av ",variable," [",units,"]"))
  
  monthly_av_filename <- paste0("location_", i, "_monthly_rate.csv")
  long_term_filename <- paste0("location_", i, "_long_term_monthly_av.csv")
  
  write.csv(monthly_av, file.path(user_wd, "results_csv", monthly_av_filename), row.names = FALSE)
  write.csv(long_term_av, file.path(user_wd, "results_csv", long_term_filename), row.names = FALSE)
  
  print(paste0("Results for location ", i, " have been saved. :)"))
}
```
